Introducci√≥n

Una vez que hayas instalado Ubuntu y configurado tu usuario, as√≠ como registrado y preparado tu entorno de trabajo, 
comienza creando la estructura inicial del proyecto con los siguientes comandos en la terminal. Esto te permitir√° organizar 
de forma ordenada las carpetas para el backend, datos, modelos, scripts, notebooks y documentaci√≥n.

cd ~/mi_proyecto_dasometria
mkdir -p app/api
mkdir -p data/raw
mkdir -p data/processed
mkdir -p models
mkdir -p notebooks
mkdir -p scripts
mkdir -p images
mkdir -p docs

Crear y editar el archivo README.md para documentar el proyecto

nano README.md

Al abrir nano, copia y pega este contenido en el editor 

Proyecto de Predicci√≥n Dasom√©tricas con Inteligencia Artificial üå≥üìê

Este repositorio contiene una aplicaci√≥n desarrollada en Ubuntu que utiliza t√©cnicas de aprendizaje autom√°tico
para predecir el Di√°metro a la Altura del Pecho (DAP) y la altura total de √°rboles a partir de im√°genes.
El backend est√° construido con FastAPI y el modelo ha sido entrenado utilizando TensorFlow/Keras.

üìÅ Estructura del Proyecto

- `app/api`: backend en FastAPI
- `data/raw`: datos sin procesar (im√°genes, CSVs)
- `data/processed`: datos preprocesados listos para entrenar
- `models`: modelos entrenados
- `scripts`: scripts de preprocesamiento y entrenamiento
- `notebooks`: notebooks de an√°lisis
- `images`: gr√°ficas y visualizaciones

‚öôÔ∏è Instalaci√≥n del Entorno

Sigue los pasos a continuaci√≥n para instalar las dependencias y preparar el entorno de desarrollo:

# Crear un entorno virtual
python3 -m venv env

# Activar el entorno virtual
source env/bin/activate

# Instalar las dependencias
pip install -r requirements.txt

üì• Datos

El conjunto de datos (im√°genes y archivo CSV con anotaciones) ser√° proporcionado por el autor del proyecto.

üöÄ Estado del Proyecto
    ‚úÖ Backend funcional con FastAPI
    ‚úÖ Modelo de IA entrenado para predicci√≥n de DAP y altura
    üîÑ Integraci√≥n con frontend en desarrollo
    üî¨ Mejora continua del dataset y del modelo
üìå Requisitos
    Python 3
    Ubuntu 20.04 o superior
    Git
    pip
üìß Contacto
Rodrigo Pedraza, Andres Villalba y Paula acosta
Estudiante de Ingenier√≠a Forestal
Universidad del Tolima
üì® rrpedrazar@ut.edu.co

Para guardar y salir de nano:

- Presiona `Ctrl + O` (te pedir√° confirmar el nombre del archivo, presiona Enter)  
- Luego `Ctrl + X` para salir  

---

Con esto ya tienes el README.md creado y guardado.

Crear el entorno virtual

python3 -m venv env

Activar el entorno virtual

source env/bin/activate

Nota: Al activar el entorno virtual, el prompt de la terminal cambiar√° y ver√°s el nombre (env) al inicio, indicando que est√°s dentro del entorno virtual.


Crear el archivo de dependencias requirements.txt

    Ejecuta el comando para abrir el editor nano y crear el archivo:

nano requirements.txt

    Dentro del editor nano, copia y pega el siguiente contenido (requerimientos del proyecto):

fastapi
uvicorn
numpy
pandas
tensorflow
python-multipart
scikit-learn
opencv-python

    Guarda y cierra el archivo nano:

    Presiona Ctrl + O para guardar.

    Presiona Enter para confirmar.

    Presiona Ctrl + X para salir.

Con el entorno virtual activado ((env) en el prompt), ejecuta el siguiente comando para instalar todas las librer√≠as listadas en requirements.txt:

pip install -r requirements.txt

PASO A PASO PARA COPIAR LAS IM√ÅGENES Y EL CSV A UBUNTU PARA HACER EL MODELO

Copiar archivos desde Windows a Ubuntu (WSL)

Abre otra terminal (CMD o PowerShell) y ejecuta el siguiente comando para copiar tus im√°genes desde Windows a Ubuntu:

wsl cp -r "/mnt/c/Users/Usuario/mi_proyecto_dasometria/images/." "/home/Usuario/mi_proyecto_dasometria/dataset/imagenes/"

Recuerda modificar la ruta a la propia donde hayas puesto tus archivos descargados 

Verifica que las im√°genes est√°n en Ubuntu

En tu terminal de Ubuntu, ejecuta:

ls dataset/imagenes

Si todo est√° correcto, deber√≠as ver algo como:

arbol1.jpg  arbol2.jpg  arbol3.jpg

MOVER EL CSV A UBUNTU

Copiar el archivo CSV desde Windows

Desde CMD o PowerShell (fuera de Ubuntu), escribe:

wsl cp "/mnt/c/Users/Usuario/mi_proyecto_dasometria/dataset/etiquetas.csv" "/home/Usuario/mi_proyecto_das

Recuerda modificar la ruta a la propia donde hayas puesto tus archivos descargados 

Verificar que el CSV est√° en Ubuntu

Desde Ubuntu:

ls dataset/etiquetas.csv

Si todo est√° bien, deber√≠as ver:

dataset/etiquetas.csv

ü§ñ CONTINUACI√ìN DEL ENTRENAMIENTO DEL MODELO
‚úÖ Paso: Crear el archivo de entrenamiento del modelo

Desde la terminal de Ubuntu:

nano entrenar_modelo.py

C√≥digo completo de entrenar_modelo.py

import os
import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split

# Ruta del CSV
csv_path = 'dataset/etiquetas.csv'
df = pd.read_csv(csv_path, delimiter=';')

# Directorio de im√°genes
image_dir = 'dataset/imagenes'

# Preprocesamiento de im√°genes y etiquetas
X = []
y = []

for index, row in df.iterrows():
    image_path = os.path.join(image_dir, row['nombre_imagen'] + '.jpg')

    if not os.path.exists(image_path):
        print(f"Imagen no encontrada: {image_path}")
        continue

    # Cargar y procesar imagen
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img) / 255.0  # Normalizaci√≥n de p√≠xeles
    X.append(img_array)

    try:
        # Reemplazar comas por puntos y convertir a float
        dap = float(str(row['dap_cm']).replace(',', '.'))
        altura = float(str(row['altura_m']).replace(',', '.'))
        y.append([dap, altura])
    except ValueError as e:
        print(f"Error en la fila {index}: {e}")

# Convertir listas a arrays
X = np.array(X)
y = np.array(y)

# Verificar que el n√∫mero de im√°genes y etiquetas coincide
print(f"Total im√°genes: {len(X)}, Total etiquetas: {len(y)}")

# Divisi√≥n entrenamiento / validaci√≥n
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir arquitectura del modelo
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(2)  # Predicci√≥n directa de DAP y altura
])

# Compilar el modelo
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])

# Entrenar el modelo
model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=8)

# Guardar el modelo entrenado
model.save('model_dasometry.h5')
print("‚úÖ Modelo guardado como model_dasometry.h5")

Guarda y cierra el archivo nano:

    Presiona Ctrl + O para guardar.

    Presiona Enter para confirmar.

    Presiona Ctrl + X para salir.

Ejecutar el entrenamiento del modelo

Una vez guardado el archivo entrenar_modelo.py, ejecuta este comando para entrenar el modelo:

python3 entrenar_modelo.py

üåê CREACI√ìN DEL SERVIDOR FASTAPI main.py
‚úÖ Paso: Crear archivo principal de la API

nano main.py

y dentro pon el siguiente c√≥digo: 

from fastapi import FastAPI, UploadFile, File, HTTPException
import numpy as np
import tensorflow as tf
from io import BytesIO
from PIL import Image, UnidentifiedImageError
import os
from pydantic import BaseModel

# Inicializar FastAPI
app = FastAPI(
    title="API de Dasometr√≠a",
    description="Predice DAP y altura a partir de una imagen de un √°rbol."
)

# Ruta al modelo entrenado
MODEL_PATH = "model_dasometry.h5"
model_loaded = False
model = None

# Intentar cargar el modelo
if os.path.exists(MODEL_PATH):
    try:
        model = tf.keras.models.load_model(MODEL_PATH)
        model_loaded = True
        print("‚úÖ Modelo cargado exitosamente")
    except Exception as e:
        print(f"‚ùå No se pudo cargar el modelo: {e}")
        model_loaded = False

# Funci√≥n para procesar la imagen
def process_image(image: Image.Image):
    image = image.resize((224, 224))        # Redimensionar a tama√±o esperado
    image = np.array(image) / 255.0         # Normalizar imagen
    image = np.expand_dims(image, axis=0)   # A√±adir dimensi√≥n para batch
    return image

# Esquema de respuesta con Pydantic
class PredictionResponse(BaseModel):
    dap_cm: float
    altura_m: float

# Ruta de predicci√≥n
@app.post("/predict/", summary="Predicci√≥n dasom√©trica", response_model=PredictionResponse)
async def predict(file: UploadFile = File(...)):
    # Verificar si el archivo es una imagen
    try:
        contents = await file.read()
        image = Image.open(BytesIO(contents)).convert("RGB")
    except UnidentifiedImageError:
        raise HTTPException(status_code=400, detail="El archivo no es una imagen v√°lida.")

    # Preprocesar imagen
    processed_image = process_image(image)

    # Ejecutar predicci√≥n
    if model_loaded:
        prediction = model.predict(processed_image)
        dap, altura = prediction[0]

        # Redondear resultados
        dap = round(float(dap), 2)
        altura = round(float(altura), 2)

        return PredictionResponse(dap_cm=dap, altura_m=altura)
    else:
        raise HTTPException(status_code=500, detail="El modelo no est√° cargado.")


Presiona Ctrl + O para guardar.

    Presiona Enter para confirmar.

    Presiona Ctrl + X para salir.

Desde el entorno virtual en tu terminal de Ubuntu:

uvicorn main:app --host 0.0.0.0 --port 8000 --reload

Esto iniciar√° un servidor en http://127.0.0.1:8000

Puedes ir a http://127.0.0.1:8000/docs para interactuar gr√°ficamente con la API.

Verificaci√≥n local

    Abre tu navegador en Ubuntu o Windows y accede a:

http://127.0.0.1:8000/docs

All√≠ ver√°s la documentaci√≥n interactiva de FastAPI.

Puedes subir una imagen y ver la predicci√≥n en tiempo real.

para detener el servidor dale ctrl + c 

OPCIONAL: Compartir la API con una URL p√∫blica usando Ngrok

En otro terminal (pesta√±a Ubuntu)

1. Descargar Ngrok

Ejecuta este comando en tu terminal para descargar el archivo .zip:

wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip

    üìÇ Esto descargar√° ngrok-stable-linux-amd64.zip en la carpeta actual (~).

Descomprimir el archivo

unzip ngrok-stable-linux-amd64.zip

    Se extraer√° el ejecutable ngrok.

Mover Ngrok a una ubicaci√≥n del sistema

sudo mv ngrok /usr/local/bin/ngrok

    Esto te permitir√° usar ngrok desde cualquier parte del sistema.

Verificar instalaci√≥n

ngrok version

Deber√≠as ver algo como:

ngrok version 3.x.x


Autenticar Ngrok con tu token

    Reg√≠strate (gratis) en: https://ngrok.com/signup

    Obt√©n tu AuthToken desde el panel de usuario.

Luego, en la terminal:

ngrok config add-authtoken TU_AUTHTOKEN_AQUI

    Reemplaza TU_AUTHTOKEN_AQUI por tu token real.

en otra Terminal: Ejecuta Ngrok

ngrok http 8000

    Ngrok generar√° una URL p√∫blica como:

https://1691-179-1-67-82.ngrok-free.app


 Puntos clave

    Ngrok redirige todo el tr√°fico al puerto 8000.

    Para ir directamente a la documentaci√≥n interactiva de tu API, agrega /docs:

https://1691-179-1-67-82.ngrok-free.app/docs

Y si quieres ir directamente al endpoint de predicci√≥n:

https://1691-179-1-67-82.ngrok-free.app/docs#/default/predict_predict__post

    üîí Ngrok no puede redirigir directamente a rutas espec√≠ficas ni fragmentos (#), eso debe hacerlo el usuario desde el navegador.
